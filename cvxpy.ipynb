{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y =make_blobs(n_samples=130, centers=2,n_features=3)\n",
    "m,n=np.shape(X)\n",
    "for i in range(len(y)):\n",
    "    if (y[i]==0):\n",
    "        y[i]=-1\n",
    "X_train=X[:100]\n",
    "y_train=y[:100]\n",
    "X_test=X[100:]\n",
    "y_test=y[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "class SVMCust:\n",
    "    def __init__(self) -> None:\n",
    "        theta=1\n",
    "        self.W=0\n",
    "        self.b=0\n",
    "        self.a=0\n",
    "        self.C=0\n",
    "        self.m=0\n",
    "    \n",
    "    def kg(self,a, b, sigma=1):\n",
    "        return np.exp((-(np.linalg.norm(a-b)**2))/(2*sigma**2))\n",
    "        # # print(\"dot:\",np.dot(a,b))\n",
    "        # # val=np.linalg.det(np.dot(a,b))\n",
    "        \n",
    "        # # print(\"as\",a.shape, \"b:\",b.shape)\n",
    "        # # print(\"a\",a,\"b\",b,\"v:\",val)\n",
    "        # return np.dot(a,b)\n",
    "    # generating kernal matrix\n",
    "    def k_mat(self,x, k_func=kg):\n",
    "        m = x.shape[0]\n",
    "        mat = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                mat[i, j] = self.kg(x[i, :], x[j, :])\n",
    "        return mat\n",
    "\n",
    "    def getAlphas(self):\n",
    "        return self.a\n",
    "    def getWeight(self):\n",
    "        return self.W\n",
    "    def getBias(self):\n",
    "        return self.b\n",
    "    def train(self,X_train,y_train):\n",
    "        print(\"shape:\",X_train.shape)\n",
    "        (m,f)=X_train.shape\n",
    "        y_train=np.asarray(y_train)\n",
    "        self.m=m\n",
    "        X=np.array(X_train)\n",
    "        # k = rbf_kernel(X)\n",
    "        k=self.k_mat(X)\n",
    "        print(np.all(np.abs(k-k.T) < 1e-08))\n",
    "        # print(k)\n",
    "        G=np.zeros((m,m))\n",
    "        print(\"shaope:\",G.shape)\n",
    "        print(\"m:\",m)\n",
    "        for i in tqdm(range(0,m)):\n",
    "            for j in range(0,m):\n",
    "                # print(\"i:\",i,\"j:\",j)\n",
    "                # print(\"s:\",(y[i]*(np.inner(X[i],np.transpose(X[j])))*y[j]).shape)\n",
    "                G[i][j]=(y_train[i]*y_train[j]*(k[i][j]))\n",
    "        # G=y*k*np.transpose(y)\n",
    "       \n",
    "\n",
    "        self.a = cp.Variable(m)\n",
    "        self.C = cp.Parameter(nonneg=True)\n",
    "        self.C.value = 0.02\n",
    "        print(\"min eigne val:\",np.linalg.eigvals(G).min())\n",
    "        # G = cp.atoms.affine.wraps.psd_wrap(G)\n",
    "        obj = cp.Minimize( (0.5) * cp.quad_form(self.a,G)-np.ones((1,m))@ self.a)\n",
    "        constraints = [0<=self.a,self.a<=self.C ,np.transpose(y_train)@self.a==0]\n",
    "        prob = cp.Problem(obj, constraints)\n",
    "        print(\"Is prob dcp:\",prob.is_dcp())\n",
    "        result = prob.solve()\n",
    "        print(self.a.value)\n",
    "        self.W=np.zeros(f,dtype='float64')\n",
    "        tempa=np.array(self.a.value)\n",
    "\n",
    "        print(tempa)\n",
    "        for i in range(m):\n",
    "            if tempa[i]==self.C.value:\n",
    "                self.W+=y_train[i]* tempa[i]* X[i]\n",
    "        cnt_pos_vec=0\n",
    "        # print(\"W:\",type(W))\n",
    "        self.W=np.asarray(self.W,dtype='float64')\n",
    "        for i in range(m):\n",
    "            if tempa[i]==self.C.value:\n",
    "                # print(X[i].dtype)\n",
    "                \n",
    "                # print(\"y:\",self.W.dtype)\n",
    "                # print(\"h\",y.dtype)\n",
    "                # print((self.W* np.transpose(X[i])).shape)\n",
    "                self.b+=y_train[i]-np.matmul(self.W, np.transpose(X[i]))\n",
    "                cnt_pos_vec+=1\n",
    "        self.b/=max(1,cnt_pos_vec)\n",
    "    def predict(self,X):\n",
    "        # ycap=np.matmul(self.W,np.transpose(X))\n",
    "        matb=np.full((X.shape[0],1),self.b)\n",
    "        matw=np.full((X.shape[0],X.shape[1]),self.W)\n",
    "        # print(matb)\n",
    "        # print(matw)\n",
    "        # print(\"shapE,\",np.matmul(X,np.transpose(self.W)).shape)\n",
    "        print(np.matmul(X,np.transpose(self.W)))\n",
    "        # print(\"fnal:,\",np.add(matb,np.matmul(X,np.transpose(self.W))).shape)\n",
    "        y_cap=self.b+np.transpose(np.matmul(X,np.transpose(self.W)))\n",
    "        print(y_cap.shape)\n",
    "        y_cap[y_cap<=0]=-1\n",
    "        y_cap[y_cap>0]=1\n",
    "        return y_cap\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.128</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.678</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>26</td>\n",
       "      <td>90</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.314</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.164</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>465</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.137</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>0.238</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.624</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>415</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.389</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "271            2      108             62             32       56  25.2   \n",
       "484            0      145              0              0        0  44.2   \n",
       "197            3      107             62             13       48  22.9   \n",
       "506            0      180             90             26       90  36.5   \n",
       "212            7      179             95             31        0  34.2   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "370            3      173             82             48      465  38.4   \n",
       "177            0      129            110             46      130  67.1   \n",
       "504            3       96             78             39        0  37.3   \n",
       "418            1       83             68              0        0  18.2   \n",
       "392            1      131             64             14      415  23.7   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "271                     0.128   21  \n",
       "484                     0.630   31  \n",
       "197                     0.678   23  \n",
       "506                     0.314   35  \n",
       "212                     0.164   60  \n",
       "..                        ...  ...  \n",
       "370                     2.137   25  \n",
       "177                     0.319   26  \n",
       "504                     0.238   40  \n",
       "418                     0.624   27  \n",
       "392                     0.389   21  \n",
       "\n",
       "[576 rows x 8 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (576, 8)\n",
      "True\n",
      "shaope: (576, 576)\n",
      "m: 576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 620.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min eigne val: (0.9999311823288843+0j)\n",
      "Is prob dcp: True\n",
      "[0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130422 0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130422 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.02       0.02\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.02       0.01130435\n",
      " 0.02       0.02       0.02       0.02       0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130411 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130436 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.02       0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.02       0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130358\n",
      " 0.01130358 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.02       0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130436 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.02       0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.02\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130411 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.02       0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435]\n",
      "[0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130422 0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130422 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.02       0.02\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.02       0.01130435\n",
      " 0.02       0.02       0.02       0.02       0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130411 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130436 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.02       0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.02       0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130358\n",
      " 0.01130358 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.02       0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130436 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.02       0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.02\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130411 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.02       0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435]\n",
      "277    137509.846309\n",
      "254    190211.302926\n",
      "620    170922.795813\n",
      "95     213499.818967\n",
      "585     78908.230142\n",
      "           ...      \n",
      "633    183755.460303\n",
      "19     140567.137793\n",
      "286    355321.461735\n",
      "557    100177.156259\n",
      "320    198613.428692\n",
      "Length: 192, dtype: float64\n",
      "(192,)\n"
     ]
    }
   ],
   "source": [
    "# scvmc=SVMCust()\n",
    "# scvmc.train(X_train,y_train)\n",
    "# print(scvmc.getAlphas().value)\n",
    "# y_test\n",
    "# scvmc.getWeight()\n",
    "# scvmc.getBias()\n",
    "# y_cap=scvmc.predict(X_test)\n",
    "# y_test\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(y_test,y_cap)\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"datasets/diabetes.csv\")\n",
    "traindt=data;\n",
    "test=data['Outcome']\n",
    "traindt.drop('Outcome',axis=1,inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(traindt,test, test_size=0.25) # 70% training and 30% test\n",
    "clf=SVMCust()\n",
    "y_train[y_train==0]=-1\n",
    "y_test[y_test==0]=-1\n",
    "clf.train(X_train, y_train)\n",
    "y_cap=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92    -1.0\n",
       "368   -1.0\n",
       "682   -1.0\n",
       "153    1.0\n",
       "442   -1.0\n",
       "      ... \n",
       "493    1.0\n",
       "121   -1.0\n",
       "527   -1.0\n",
       "402   -1.0\n",
       "675   -1.0\n",
       "Length: 192, dtype: float64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging.config import valid_ident\n",
    "from cvxpy import Problem\n",
    "from tqdm import tqdm\n",
    "class FairSVM:\n",
    "    def __init__(self):\n",
    "        self.W=[]\n",
    "        self.b=[]\n",
    "        self.a=[]\n",
    "        self.C=[]\n",
    "        self.m=0\n",
    "    def kg(self,a, b, sigma=1):\n",
    "        return np.exp((-(np.linalg.norm(a-b)**2))/(2*sigma**2))\n",
    "\n",
    "    # generating kernal matrix\n",
    "    def k_mat(self,x, k_func=kg):\n",
    "        m = x.shape[0]\n",
    "        mat = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                mat[i, j] = self.kg(x[i, :], x[j, :])\n",
    "        return mat\n",
    "\n",
    "    def getAlphas(self):\n",
    "        return self.a\n",
    "    def getWeight(self):\n",
    "        return self.W\n",
    "    def getBias(self):\n",
    "        return self.b\n",
    "    def fit(self,X_train,Y_train,list_of_sensetive_attr):\n",
    "        (m,n)=X_train.shape\n",
    "        y_train[y_train==0]=-1\n",
    "        print(\"m:\",m)\n",
    "        Z=X_train.copy()\n",
    "        non_sensetive_fet=[x for x in list(Z.columns) if x not in list_of_sensetive_attr]\n",
    "        Z.drop( non_sensetive_fet,axis=1,inplace=True)\n",
    "        X_train.drop( list_of_sensetive_attr, axis=1, inplace=True)\n",
    "        print(\"dropped fet:\")\n",
    "        Z=np.asarray(Z)\n",
    "        \n",
    "        Galpha=np.zeros(m)\n",
    "        Halpha=np.zeros(m)\n",
    "        self.m=m\n",
    "\n",
    "        X=np.array(X_train)\n",
    "        # X = np.hstack((X, np.ones([m,1])))   \n",
    "        # k = rbf_kernel(X)\n",
    "        k=self.k_mat(X)\n",
    "        # print(k)\n",
    "        self.a = cp.Variable(m)\n",
    "        self.C = cp.Parameter(nonneg=True)\n",
    "        self.C.value = 1\n",
    "        deltamat=np.zeros((m,m))\n",
    "        print(self.C.value)\n",
    "        # print(deltamat.value)\n",
    "        print(\"h1:\")\n",
    "        for i in range (m):\n",
    "            for j in range(m):\n",
    "                if i==j:\n",
    "                    deltamat[i][j]=(1/self.C.value)**1\n",
    "                else:\n",
    "                     deltamat[i][j]=1\n",
    "        # objective=cp.Minimize(cp.sum(a)+ cp.sum(cp.multiply(a,y))\n",
    "        res=0\n",
    "        cres=0\n",
    "        print(\"starting main loop:\")\n",
    "        for i in range(m):\n",
    "            res+= self.a[i]+ \\\n",
    "            self.a[i]*y[i]*( cp.sum(cp.multiply(cp.multiply(self.a,y),k[i]))+ cp.sum(cp.multiply(cp.multiply(self.a,y),deltamat[i])))\n",
    "            cres=(Z[i]-np.mean(Z))*cp.sum(cp.multiply(cp.multiply(self.a,y),k[i]))\n",
    "        print(\"res:\",res)\n",
    "        objective=cp.Minimize(res)\n",
    "        constraints=[cp.sum(cp.multiply(self.a,y))==0 , cres>= (-1)*self.C*m, cres <=self.C*m ]\n",
    "        prob=cp.Problem(objective,constraints)\n",
    "        print(\"is dcp:\",prob.is_dcp())\n",
    "        print(\"status:\",prob.status)\n",
    "        # prob.solve()\n",
    "            # for j in range(m):\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y =make_blobs(n_samples=2, centers=2,n_features=2)\n",
    "m,n=np.shape(X)\n",
    "# for i in range(len(y)):\n",
    "#     if (y[i]==0):\n",
    "#         y[i]=-1\n",
    "X_train=X\n",
    "y_train=y\n",
    "X_test=X[1500:]\n",
    "y_test=y[1500:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyparsing import col\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.DataFrame(data=X_train,columns=['a','b'])\n",
    "data['one']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'one']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sensetive_fet=['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.035372</td>\n",
       "      <td>-4.111227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.401441</td>\n",
       "      <td>-6.077333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b  one\n",
       "0  2.035372 -4.111227    1\n",
       "1  1.401441 -6.077333    1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsvm=FairSVM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 2\n",
      "dropped fet:\n",
      "1\n",
      "h1:\n",
      "starting main loop:\n",
      "res: var1009[0] + var1009[0] @ -1.0 @ (Sum(var1009 @ [-1.  1.] @ [1.         0.81796646], None, False) + Sum(var1009 @ [-1.  1.] @ [1. 1.], None, False)) + var1009[1] + var1009[1] @ 1.0 @ (Sum(var1009 @ [-1.  1.] @ [0.81796646 1.        ], None, False) + Sum(var1009 @ [-1.  1.] @ [1. 1.], None, False))\n",
      "is dcp: False\n",
      "status: None\n"
     ]
    }
   ],
   "source": [
    "fsvm.fit(data,y_test,list_of_sensetive_fet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e63ba49aebc988b646e1dbf99c75ebbbe79a20618136c52c827b2893e897d8ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
