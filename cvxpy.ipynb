{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.2-cp310-cp310-win_amd64.whl (7.4 MB)\n",
      "     ---------------------------------------- 7.4/7.4 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     -------------------------------------- 298.0/298.0 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.9.1)\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn, sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.1.2 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection  import train_test_split\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y =make_blobs(n_samples=130, centers=2,n_features=3)\n",
    "m,n=np.shape(X)\n",
    "for i in range(len(y)):\n",
    "    if (y[i]==0):\n",
    "        y[i]=-1\n",
    "X_train=X[:100]\n",
    "y_train=y[:100]\n",
    "X_test=X[100:]\n",
    "y_test=y[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "class SVMCust:\n",
    "    def __init__(self) -> None:\n",
    "        theta=1\n",
    "        self.W=0\n",
    "        self.b=0\n",
    "        self.a=0\n",
    "        self.C=0\n",
    "        self.m=0\n",
    "    \n",
    "    def kg(self,a, b, sigma=1):\n",
    "        return np.exp((-(np.linalg.norm(a-b)**2))/(2*sigma**2))\n",
    "        # # print(\"dot:\",np.dot(a,b))\n",
    "        # # val=np.linalg.det(np.dot(a,b))\n",
    "        \n",
    "        # # print(\"as\",a.shape, \"b:\",b.shape)\n",
    "        # # print(\"a\",a,\"b\",b,\"v:\",val)\n",
    "        # return np.dot(a,b)\n",
    "    # generating kernal matrix\n",
    "    def k_mat(self,x, k_func=kg):\n",
    "        m = x.shape[0]\n",
    "        mat = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                mat[i, j] = self.kg(x[i, :], x[j, :])\n",
    "        return mat\n",
    "\n",
    "    def getAlphas(self):\n",
    "        return self.a\n",
    "    def getWeight(self):\n",
    "        return self.W\n",
    "    def getBias(self):\n",
    "        return self.b\n",
    "    def train(self,X_train,y_train):\n",
    "        print(\"shape:\",X_train.shape)\n",
    "        (m,f)=X_train.shape\n",
    "        y_train=np.asarray(y_train)\n",
    "        self.m=m\n",
    "        X=np.array(X_train)\n",
    "        # k = rbf_kernel(X)\n",
    "        k=self.k_mat(X)\n",
    "        print(np.all(np.abs(k-k.T) < 1e-08))\n",
    "        # print(k)\n",
    "        G=np.zeros((m,m))\n",
    "        print(\"shaope:\",G.shape)\n",
    "        print(\"m:\",m)\n",
    "        for i in tqdm(range(0,m)):\n",
    "            for j in range(0,m):\n",
    "                # print(\"i:\",i,\"j:\",j)\n",
    "                # print(\"s:\",(y[i]*(np.inner(X[i],np.transpose(X[j])))*y[j]).shape)\n",
    "                G[i][j]=(y_train[i]*y_train[j]*(k[i][j]))\n",
    "        # G=y*k*np.transpose(y)\n",
    "       \n",
    "\n",
    "        self.a = cp.Variable(m)\n",
    "        self.C = cp.Parameter(nonneg=True)\n",
    "        self.C.value = 0.02\n",
    "        print(\"min eigne val:\",np.linalg.eigvals(G).min())\n",
    "        # G = cp.atoms.affine.wraps.psd_wrap(G)\n",
    "        obj = cp.Minimize( (0.5) * cp.quad_form(self.a,G)-np.ones((1,m))@ self.a)\n",
    "        constraints = [0<=self.a,self.a<=self.C ,np.transpose(y_train)@self.a==0]\n",
    "        prob = cp.Problem(obj, constraints)\n",
    "        print(\"Is prob dcp:\",prob.is_dcp())\n",
    "        result = prob.solve()\n",
    "        print(self.a.value)\n",
    "        self.W=np.zeros(f,dtype='float64')\n",
    "        tempa=np.array(self.a.value)\n",
    "\n",
    "        print(tempa)\n",
    "        for i in range(m):\n",
    "            if tempa[i]==self.C.value:\n",
    "                self.W+=y_train[i]* tempa[i]* X[i]\n",
    "        cnt_pos_vec=0\n",
    "        # print(\"W:\",type(W))\n",
    "        self.W=np.asarray(self.W,dtype='float64')\n",
    "        for i in range(m):\n",
    "            if tempa[i]==self.C.value:\n",
    "                # print(X[i].dtype)\n",
    "                \n",
    "                # print(\"y:\",self.W.dtype)\n",
    "                # print(\"h\",y.dtype)\n",
    "                # print((self.W* np.transpose(X[i])).shape)\n",
    "                self.b+=y_train[i]-np.matmul(self.W, np.transpose(X[i]))\n",
    "                cnt_pos_vec+=1\n",
    "        self.b/=max(1,cnt_pos_vec)\n",
    "    def predict(self,X):\n",
    "        # ycap=np.matmul(self.W,np.transpose(X))\n",
    "        matb=np.full((X.shape[0],1),self.b)\n",
    "        matw=np.full((X.shape[0],X.shape[1]),self.W)\n",
    "        # print(matb)\n",
    "        # print(matw)\n",
    "        # print(\"shapE,\",np.matmul(X,np.transpose(self.W)).shape)\n",
    "        print(np.matmul(X,np.transpose(self.W)))\n",
    "        # print(\"fnal:,\",np.add(matb,np.matmul(X,np.transpose(self.W))).shape)\n",
    "        y_cap=self.b+np.transpose(np.matmul(X,np.transpose(self.W)))\n",
    "        print(y_cap.shape)\n",
    "        y_cap[y_cap<=0]=-1\n",
    "        y_cap[y_cap>0]=1\n",
    "        return y_cap\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.128</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.678</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>26</td>\n",
       "      <td>90</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.314</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.164</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>465</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.137</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>0.238</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.624</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>415</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.389</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "271            2      108             62             32       56  25.2   \n",
       "484            0      145              0              0        0  44.2   \n",
       "197            3      107             62             13       48  22.9   \n",
       "506            0      180             90             26       90  36.5   \n",
       "212            7      179             95             31        0  34.2   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "370            3      173             82             48      465  38.4   \n",
       "177            0      129            110             46      130  67.1   \n",
       "504            3       96             78             39        0  37.3   \n",
       "418            1       83             68              0        0  18.2   \n",
       "392            1      131             64             14      415  23.7   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "271                     0.128   21  \n",
       "484                     0.630   31  \n",
       "197                     0.678   23  \n",
       "506                     0.314   35  \n",
       "212                     0.164   60  \n",
       "..                        ...  ...  \n",
       "370                     2.137   25  \n",
       "177                     0.319   26  \n",
       "504                     0.238   40  \n",
       "418                     0.624   27  \n",
       "392                     0.389   21  \n",
       "\n",
       "[576 rows x 8 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (576, 8)\n",
      "True\n",
      "shaope: (576, 576)\n",
      "m: 576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 620.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min eigne val: (0.9999311823288843+0j)\n",
      "Is prob dcp: True\n",
      "[0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130422 0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130422 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.02       0.02\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.02       0.01130435\n",
      " 0.02       0.02       0.02       0.02       0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130411 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130436 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.02       0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.02       0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130358\n",
      " 0.01130358 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.02       0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130436 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.02       0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.02\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130411 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.02       0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435]\n",
      "[0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130422 0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130422 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.02       0.02\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.02       0.01130435\n",
      " 0.02       0.02       0.02       0.02       0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130411 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130436 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.02       0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.02       0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130358\n",
      " 0.01130358 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.02       0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130436 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.02       0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.02\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.02       0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.02       0.02       0.02       0.01130435 0.02       0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.02       0.02       0.01130435 0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.02       0.01130435 0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130411 0.02       0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.02\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.01130435 0.02       0.02\n",
      " 0.01130435 0.02       0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.01130435 0.02       0.01130435 0.02       0.02       0.02\n",
      " 0.01130435 0.02       0.02       0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.02       0.02       0.01130435 0.02\n",
      " 0.01130435 0.01130435 0.01130435 0.02       0.01130435 0.01130435\n",
      " 0.02       0.01130435 0.01130435 0.01130435 0.01130435 0.01130435]\n",
      "277    137509.846309\n",
      "254    190211.302926\n",
      "620    170922.795813\n",
      "95     213499.818967\n",
      "585     78908.230142\n",
      "           ...      \n",
      "633    183755.460303\n",
      "19     140567.137793\n",
      "286    355321.461735\n",
      "557    100177.156259\n",
      "320    198613.428692\n",
      "Length: 192, dtype: float64\n",
      "(192,)\n"
     ]
    }
   ],
   "source": [
    "# scvmc=SVMCust()\n",
    "# scvmc.train(X_train,y_train)\n",
    "# print(scvmc.getAlphas().value)\n",
    "# y_test\n",
    "# scvmc.getWeight()\n",
    "# scvmc.getBias()\n",
    "# y_cap=scvmc.predict(X_test)\n",
    "# y_test\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(y_test,y_cap)\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"datasets/diabetes.csv\")\n",
    "traindt=data;\n",
    "test=data['Outcome']\n",
    "traindt.drop('Outcome',axis=1,inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(traindt,test, test_size=0.25) # 70% training and 30% test\n",
    "clf=SVMCust()\n",
    "y_train[y_train==0]=-1\n",
    "y_test[y_test==0]=-1\n",
    "clf.train(X_train, y_train)\n",
    "y_cap=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92    -1.0\n",
       "368   -1.0\n",
       "682   -1.0\n",
       "153    1.0\n",
       "442   -1.0\n",
       "      ... \n",
       "493    1.0\n",
       "121   -1.0\n",
       "527   -1.0\n",
       "402   -1.0\n",
       "675   -1.0\n",
       "Length: 192, dtype: float64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dccp in c:\\python310\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: cvxpy>=0.3.5 in c:\\python310\\lib\\site-packages (from dccp) (1.2.1)\n",
      "Requirement already satisfied: ecos>=2 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (2.0.10)\n",
      "Requirement already satisfied: scs>=1.1.6 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (1.23.3)\n",
      "Requirement already satisfied: osqp>=0.4.1 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (0.6.2.post5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (1.9.1)\n",
      "Requirement already satisfied: qdldl in c:\\python310\\lib\\site-packages (from osqp>=0.4.1->cvxpy>=0.3.5->dccp) (0.1.5.post2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install dccp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.5.0-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "     ---------------------------------------- 10.4/10.4 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.4-py2.py3-none-any.whl (500 kB)\n",
      "     -------------------------------------- 500.8/500.8 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\python310\\lib\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.5.0 pytz-2022.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging.config import valid_ident\n",
    "from cvxpy import Problem\n",
    "import dccp\n",
    "from tqdm import tqdm\n",
    "class FairSVM:\n",
    "    def __init__(self):\n",
    "        self.W=[]\n",
    "        self.b=[]\n",
    "        self.a=[]\n",
    "        self.C=[]\n",
    "        self.m=0\n",
    "    def kg(self,a, b, sigma=1):\n",
    "        return np.exp((-(np.linalg.norm(a-b)**2))/(2*sigma**2))\n",
    "\n",
    "    # generating kernal matrix\n",
    "    def k_mat(self,x, k_func=kg):\n",
    "        m = x.shape[0]\n",
    "        mat = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                mat[i, j] = self.kg(x[i, :], x[j, :])\n",
    "        return mat\n",
    "\n",
    "    def getAlphas(self):\n",
    "        return self.a\n",
    "    def getWeight(self):\n",
    "        return self.W\n",
    "    def getBias(self):\n",
    "        return self.b\n",
    "    def fit(self,X_train,Y_train,list_of_sensetive_attr):\n",
    "        (m,n)=X_train.shape\n",
    "        y_train[y_train==0]=-1\n",
    "        print(\"m:\",m)\n",
    "        Z=X_train.copy()\n",
    "        non_sensetive_fet=[x for x in list(Z.columns) if x not in list_of_sensetive_attr]\n",
    "        Z.drop( non_sensetive_fet,axis=1,inplace=True)\n",
    "        X_train.drop( list_of_sensetive_attr, axis=1, inplace=True)\n",
    "        print(\"dropped fet:\")\n",
    "        Z=np.asarray(Z)\n",
    "        \n",
    "        Galpha=np.zeros(m)\n",
    "        Halpha=np.zeros(m)\n",
    "        self.m=m\n",
    "\n",
    "        X=np.array(X_train)\n",
    "        # X = np.hstack((X, np.ones([m,1])))   \n",
    "        # k = rbf_kernel(X)\n",
    "        k=self.k_mat(X)\n",
    "        # print(k)\n",
    "        self.a = cp.Variable(m)\n",
    "        self.C = cp.Parameter(nonneg=True)\n",
    "        self.C.value = 1\n",
    "        deltamat=np.zeros((m,m))\n",
    "        print(self.C.value)\n",
    "        # print(deltamat.value)\n",
    "        print(\"h1:\")\n",
    "        for i in range (m):\n",
    "            for j in range(m):\n",
    "                if i==j:\n",
    "                    deltamat[i][j]=(1/self.C.value)\n",
    "                else:\n",
    "                     deltamat[i][j]=0\n",
    "        # objective=cp.Minimize(cp.sum(a)+ cp.sum(cp.multiply(a,y))\n",
    "        res=0\n",
    "        cres=0\n",
    "        print(\"starting main loop:\")\n",
    "        for i in range(m):\n",
    "            res+= self.a[i]+ \\\n",
    "            self.a[i]*y[i]*( cp.sum(cp.multiply(cp.multiply(self.a,y),k[i]))+ cp.sum(cp.multiply(cp.multiply(self.a,y),deltamat[i])))\n",
    "            cres=(Z[i]-np.mean(Z))*cp.sum(cp.multiply(cp.multiply(self.a,y),k[i]))\n",
    "        print(\"res:\",res)\n",
    "        objective=cp.Minimize(res)\n",
    "        constraints=[cp.sum(cp.multiply(self.a,y))==0 , cres>= (-1)*self.C*m, cres <=self.C*m ]\n",
    "        prob=cp.Problem(objective,constraints)\n",
    "        print(\"is dcp:\",prob.is_dcp())\n",
    "        print(\"is dccp:\",dccp.is_dccp(prob))\n",
    "        print(\"status:\",prob.status)\n",
    "        # prob.solve()\n",
    "            # for j in range(m):\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y =make_blobs(n_samples=2, centers=2,n_features=2)\n",
    "m,n=np.shape(X)\n",
    "# for i in range(len(y)):\n",
    "#     if (y[i]==0):\n",
    "#         y[i]=-1\n",
    "X_train=X\n",
    "y_train=y\n",
    "X_test=X[1500:]\n",
    "y_test=y[1500:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyparsing import col\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.DataFrame(data=X_train,columns=['a','b'])\n",
    "data['one']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'one']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sensetive_fet=['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.763208</td>\n",
       "      <td>-5.393358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.423112</td>\n",
       "      <td>-5.404680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           a         b  one\n",
       "0 -10.763208 -5.393358    1\n",
       "1  -2.423112 -5.404680    1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsvm=FairSVM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 2\n",
      "dropped fet:\n",
      "1\n",
      "h1:\n",
      "starting main loop:\n",
      "res: var413[0] + 1.0 @ (Sum(power(var413, 2.0) @ [ 1. -1.] @ [1.00000000e+00 7.86765846e-16], None, False) + Sum(power(var413, 2.0) @ [ 1. -1.] @ [1. 0.], None, False)) + var413[1] + -1.0 @ (Sum(power(var413, 2.0) @ [ 1. -1.] @ [7.86765846e-16 1.00000000e+00], None, False) + Sum(power(var413, 2.0) @ [ 1. -1.] @ [0. 1.], None, False))\n",
      "is dcp: False\n",
      "is dccp: False\n",
      "status: None\n"
     ]
    },
    {
     "ename": "DCPError",
     "evalue": "Problem does not follow DCP rules. Specifically:\nThe objective is not DCP. Its following subexpressions are not:\npower(var413, 2.0) @ [ 1. -1.]\npower(var413, 2.0) @ [ 1. -1.]\npower(var413, 2.0) @ [ 1. -1.]\npower(var413, 2.0) @ [ 1. -1.]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDCPError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [98], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fsvm\u001b[38;5;241m.\u001b[39mfit(data,y_test,list_of_sensetive_fet)\n",
      "Cell \u001b[1;32mIn [90], line 78\u001b[0m, in \u001b[0;36mFairSVM.fit\u001b[1;34m(self, X_train, Y_train, list_of_sensetive_attr)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis dccp:\u001b[39m\u001b[38;5;124m\"\u001b[39m,dccp\u001b[38;5;241m.\u001b[39mis_dccp(prob))\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus:\u001b[39m\u001b[38;5;124m\"\u001b[39m,prob\u001b[38;5;241m.\u001b[39mstatus)\n\u001b[1;32m---> 78\u001b[0m \u001b[43mprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\cvxpy\\problems\\problem.py:481\u001b[0m, in \u001b[0;36mProblem.solve\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m     solve_func \u001b[39m=\u001b[39m Problem\u001b[39m.\u001b[39m_solve\n\u001b[1;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m solve_func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\cvxpy\\problems\\problem.py:1007\u001b[0m, in \u001b[0;36mProblem._solve\u001b[1;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, **kwargs)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munpack(chain\u001b[39m.\u001b[39mretrieve(soln))\n\u001b[0;32m   1005\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue\n\u001b[1;32m-> 1007\u001b[0m data, solving_chain, inverse_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_problem_data(\n\u001b[0;32m   1008\u001b[0m     solver, gp, enforce_dpp, ignore_dpp, verbose)\n\u001b[0;32m   1010\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m   1011\u001b[0m     \u001b[39mprint\u001b[39m(_NUM_SOLVER_STR)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\cvxpy\\problems\\problem.py:607\u001b[0m, in \u001b[0;36mProblem.get_problem_data\u001b[1;34m(self, solver, gp, enforce_dpp, ignore_dpp, verbose)\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mkey:\n\u001b[0;32m    606\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39minvalidate()\n\u001b[1;32m--> 607\u001b[0m     solving_chain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_chain(\n\u001b[0;32m    608\u001b[0m         solver\u001b[39m=\u001b[39;49msolver, gp\u001b[39m=\u001b[39;49mgp,\n\u001b[0;32m    609\u001b[0m         enforce_dpp\u001b[39m=\u001b[39;49menforce_dpp,\n\u001b[0;32m    610\u001b[0m         ignore_dpp\u001b[39m=\u001b[39;49mignore_dpp)\n\u001b[0;32m    611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mkey \u001b[39m=\u001b[39m key\n\u001b[0;32m    612\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39msolving_chain \u001b[39m=\u001b[39m solving_chain\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\cvxpy\\problems\\problem.py:845\u001b[0m, in \u001b[0;36mProblem._construct_chain\u001b[1;34m(self, solver, gp, enforce_dpp, ignore_dpp)\u001b[0m\n\u001b[0;32m    843\u001b[0m candidate_solvers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_candidate_solvers(solver\u001b[39m=\u001b[39msolver, gp\u001b[39m=\u001b[39mgp)\n\u001b[0;32m    844\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sort_candidate_solvers(candidate_solvers)\n\u001b[1;32m--> 845\u001b[0m \u001b[39mreturn\u001b[39;00m construct_solving_chain(\u001b[39mself\u001b[39;49m, candidate_solvers, gp\u001b[39m=\u001b[39;49mgp,\n\u001b[0;32m    846\u001b[0m                                enforce_dpp\u001b[39m=\u001b[39;49menforce_dpp,\n\u001b[0;32m    847\u001b[0m                                ignore_dpp\u001b[39m=\u001b[39;49mignore_dpp)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:162\u001b[0m, in \u001b[0;36mconstruct_solving_chain\u001b[1;34m(problem, candidates, gp, enforce_dpp, ignore_dpp)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(problem\u001b[39m.\u001b[39mvariables()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m SolvingChain(reductions\u001b[39m=\u001b[39m[ConstantSolver()])\n\u001b[1;32m--> 162\u001b[0m reductions \u001b[39m=\u001b[39m _reductions_for_problem_class(problem, candidates, gp)\n\u001b[0;32m    164\u001b[0m \u001b[39m# Process DPP status of the problem.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m dpp_context \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdcp\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m gp \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdgp\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:94\u001b[0m, in \u001b[0;36m_reductions_for_problem_class\u001b[1;34m(problem, candidates, gp)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39melif\u001b[39;00m problem\u001b[39m.\u001b[39mis_dqcp():\n\u001b[0;32m     92\u001b[0m         append \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mHowever, the problem does follow DQCP rules. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mConsider calling solve() with `qcp=True`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mraise\u001b[39;00m DCPError(\n\u001b[0;32m     95\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mProblem does not follow DCP rules. Specifically:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m append)\n\u001b[0;32m     96\u001b[0m \u001b[39melif\u001b[39;00m gp \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m problem\u001b[39m.\u001b[39mis_dgp():\n\u001b[0;32m     97\u001b[0m     append \u001b[39m=\u001b[39m build_non_disciplined_error_msg(problem, \u001b[39m'\u001b[39m\u001b[39mDGP\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mDCPError\u001b[0m: Problem does not follow DCP rules. Specifically:\nThe objective is not DCP. Its following subexpressions are not:\npower(var413, 2.0) @ [ 1. -1.]\npower(var413, 2.0) @ [ 1. -1.]\npower(var413, 2.0) @ [ 1. -1.]\npower(var413, 2.0) @ [ 1. -1.]"
     ]
    }
   ],
   "source": [
    "fsvm.fit(data,y_test,list_of_sensetive_fet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: dccp 1.0.4\n",
      "Uninstalling dccp-1.0.4:\n",
      "  Successfully uninstalled dccp-1.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall dccp --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dccp\n",
      "  Using cached dccp-1.0.4.tar.gz (8.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: cvxpy>=0.3.5 in c:\\python310\\lib\\site-packages (from dccp) (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (1.9.1)\n",
      "Requirement already satisfied: scs>=1.1.6 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (1.23.3)\n",
      "Requirement already satisfied: ecos>=2 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (2.0.10)\n",
      "Requirement already satisfied: osqp>=0.4.1 in c:\\python310\\lib\\site-packages (from cvxpy>=0.3.5->dccp) (0.6.2.post5)\n",
      "Requirement already satisfied: qdldl in c:\\python310\\lib\\site-packages (from osqp>=0.4.1->cvxpy>=0.3.5->dccp) (0.1.5.post2)\n",
      "Using legacy 'setup.py install' for dccp, since package 'wheel' is not installed.\n",
      "Installing collected packages: dccp\n",
      "  Running setup.py install for dccp: started\n",
      "  Running setup.py install for dccp: finished with status 'done'\n",
      "Successfully installed dccp-1.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install dccp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dccp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
